{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOQDdT2QQfAR"
   },
   "source": [
    "# Treino do zero (*from scratch*)\n",
    "\n",
    "Neste script vamos conhecer a estratégia de treino tradicional de redes neurais em geral: **O treino do zero (*from scratch*)**. <br>\n",
    "Trataremos do uso mais tradicional de CNNs: **classificação de imagens**.\n",
    "\n",
    "\n",
    "Primeiro de tudo, vamos fazer os imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821e85d",
   "metadata": {
    "name": "seed"
   },
   "outputs": [],
   "source": [
    "# >>> Determinismo / Sementes\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Para resultados mais reprodutíveis (pode reduzir performance em GPU)\n",
    "torch.use_deterministic_algorithms(False)  # deixe True se quiser máximo determinismo\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_B0cddsU33Y"
   },
   "outputs": [],
   "source": [
    "# Implementação e treinamento da rede\n",
    "\n",
    "# Importa o núcleo do PyTorch (tensores, CUDA, etc.).\n",
    "import torch\n",
    "\n",
    "# Traz os submódulos de redes neurais (nn) e otimizadores (optim).\n",
    "from torch import nn, optim\n",
    "# Agendadores de taxa de aprendizado.\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Carregamento de Dados\n",
    "\n",
    "# Utilitário para criar DataLoaders (mini-batches, shuffle, workers paralelos).\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Datasets prontos (CIFAR-10, MNIST, etc.) do torchvision.\n",
    "from torchvision import datasets\n",
    "\n",
    "# Transforms para pré-processamento/augmentação (ToTensor, Normalize, Resize, ...).\n",
    "from torchvision import transforms\n",
    "\n",
    "# Seção de organização do script: métricas e visualização.\n",
    "# Plots e análises\n",
    "\n",
    "# Métrica de acurácia do scikit-learn.\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Biblioteca de gráficos.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualização de matrizes em formato de heatmap.\n",
    "import seaborn as sns\n",
    "\n",
    "# Operações numéricas e arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Medição de tempo e utilidades do SO (paths, variáveis de ambiente, etc.).\n",
    "import time, os\n",
    "\n",
    "# (Apenas em Jupyter) Renderiza gráficos do Matplotlib embutidos nas células.\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BCFjDoZr5aU7",
    "outputId": "ce85ed84-e42d-4d64-c097-adc97baba5a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Define os hiperparâmetros do treinamento em um dicionário.\n",
    "args = {\n",
    "    # Número total de épocas (passagens completas pelo dataset).\n",
    "    'epoch_num': 150,     # Número de épocas.\n",
    "    # Taxa de aprendizado inicial do otimizador.\n",
    "    'lr': 1e-3,           # Taxa de aprendizado.\n",
    "    # Penalidade L2 aplicada aos pesos para reduzir overfitting.\n",
    "    #    'weight_decay': 1e-3, # Penalidade L2 (Regularização).\n",
    "    'weight_decay': 5e-3, # Penalidade L2 (Regularização).\n",
    "    # Quantidade de amostras processadas por iteração.\n",
    "    'batch_size': 50,     # Tamanho do batch.\n",
    "}\n",
    "\n",
    "# Verifica se há GPU CUDA disponível para acelerar o treinamento.\n",
    "# Definindo dispositivo de hardware\n",
    "# if torch.cuda.is_available():\n",
    "#     # Se houver CUDA, usa a GPU.\n",
    "#     args['device'] = torch.device('cuda')\n",
    "# else:\n",
    "#     # Caso contrário, recorre à CPU.\n",
    "#     args['device'] = torch.device('cpu')\n",
    "\n",
    "args['device'] = torch.device('cpu')\n",
    "\n",
    "# Mostra no console qual dispositivo foi selecionado.\n",
    "print(args['device'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqNPF0VmGZma"
   },
   "source": [
    "## Carregamento de Dados\n",
    "\n",
    "Usaremos o dataset [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html), um conjunto de imagens RGB divididas em 10 categorias de objeto: avião, automóvel, pássaro, gato, veado, cachorro, sapo, cavalo, navio, caminhão. As imagens possuem $32 \\times 32$ pixels.\n",
    "\n",
    "Trata-se de um dataset de 60 mil imagens naturais (do mundo real), muito utilizado para avaliar a qualidade de modelos de aprendizado profundo.\n",
    "\n",
    "https://pytorch.org/docs/stable/torchvision/datasets.html#cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8M1qzFIc58Y3",
    "outputId": "6d139741-d363-47b0-8c1c-4841470b3c1f"
   },
   "outputs": [],
   "source": [
    "# Pipeline de transformações para TREINO e TESTE.\n",
    "# Importa utilitários de pré-processamento/augmentação de imagens do torchvision.\n",
    "from torchvision import transforms\n",
    "\n",
    "# Médias por canal (R, G, B) do CIFAR-10 para normalização.\n",
    "MEAN = (0.4914, 0.4822, 0.4465)\n",
    "\n",
    "# Desvios-padrão por canal (R, G, B) do CIFAR-10 para normalização.\n",
    "STD  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "# Pipeline de transformações para TREINO: inclui aumentos de dados + normalização.\n",
    "train_transform = transforms.Compose([\n",
    "    # Crop aleatório 32×32 com padding=2; bordas preenchidas por reflexão (reduz overfitting).\n",
    "    transforms.RandomCrop(32, padding=2, padding_mode='reflect'),\n",
    "    # Flip horizontal aleatório com probabilidade de 40% (aumenta variação espacial).\n",
    "    transforms.RandomHorizontalFlip(p=0.4),\n",
    "    # Converte PIL/NumPy para Tensor (C×H×W) com valores em [0,1].\n",
    "    transforms.ToTensor(),\n",
    "    # Normaliza cada canal usando as estatísticas definidas acima (acelera/estabiliza o treino).\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "# Pipeline de transformações para TESTE: apenas conversão + normalização (sem augmentações).\n",
    "test_transform = transforms.Compose([\n",
    "    # Converte para Tensor mantendo a imagem intacta (sem aleatoriedade).\n",
    "    transforms.ToTensor(),\n",
    "    # Aplica a mesma normalização do treino para consistência.\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "# Instancia o dataset CIFAR-10 para TREINO no diretório atual.\n",
    "train_set = datasets.CIFAR10('.', \n",
    "# Seleciona o split de treino.\n",
    "                      train=True, \n",
    "# Aplica o pipeline de transformações com aumento de dados.\n",
    "                      transform=train_transform, \n",
    "# Faz o download se os arquivos não existirem localmente; fecha a chamada.\n",
    "                      download=True)\n",
    "\n",
    "# Instancia o dataset CIFAR-10 para TESTE no diretório atual.\n",
    "test_set = datasets.CIFAR10('.', \n",
    "# Seleciona o split de teste.\n",
    "                      train=False, \n",
    "# Usa o pipeline determinístico (sem augmentations) para avaliação.\n",
    "                      transform=test_transform, \n",
    "# Não força novo download (assume que já foi feito no train).\n",
    "                      download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "colab_type": "code",
    "id": "Oi-sd2Xq7LJz",
    "outputId": "357ecbca-a108-4a4b-8d44-26c639fc8026"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.1770618..2.6952004].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.4290657..2.5976489].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.351526..2.6952004].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7692488..2.3440151].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.2933714..1.908451].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.3395875..1.6611518].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.4096808..2.7537313].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.0458004..2.7147107].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.1035852..2.518123].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.024918..2.6756902].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cria uma figura com 1 linha e 10 subplots; o tamanho total é 20×2 polegadas.\n",
    "fig, axs = plt.subplots(1,10, figsize=(20, 2))\n",
    "\n",
    "# Itera sobre as 10 primeiras amostras do conjunto de teste.\n",
    "for i in range(10):\n",
    "  # Obtém a imagem (tensor) e o rótulo correspondente no índice i.\n",
    "  data, label = test_set[i]\n",
    "  # Converte de C×H×W para H×W×C para exibir corretamente com o Matplotlib.\n",
    "  axs[i].imshow(data.permute((1,2,0)))\n",
    "  # Remove os eixos para uma visualização limpa.\n",
    "  axs[i].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVEf-GCDHtNf"
   },
   "outputs": [],
   "source": [
    "# Cria o DataLoader do conjunto de TREINO; entrega lotes do train_set ao modelo.\n",
    "train_loader = DataLoader(train_set, \n",
    "# Tamanho do mini-batch definido nos hiperparâmetros.\n",
    "                          batch_size=args['batch_size'], \n",
    "# Embaralha a ordem dos exemplos a cada época (boa prática no treino).\n",
    "                          shuffle=True)\n",
    "\n",
    "# Cria o DataLoader do conjunto de TESTE/validação.\n",
    "test_loader = DataLoader(test_set, \n",
    "# Usa o mesmo tamanho de lote para avaliação.\n",
    "                          batch_size=args['batch_size'], \n",
    "# Aqui está como True; em geral usa-se shuffle=False no teste para reprodutibilidade.\n",
    "                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2itzENY29Ty"
   },
   "source": [
    "## LeNet 5\n",
    "\n",
    "Primeiro de tudo, precisamos **implementar uma CNN**. Sim, chegou a hora de colocar em prática tudo que já sabemos sobre redes convolucionais, montando uma arquitetura completa!\n",
    "\n",
    "A arquitetura escolhida para essa aula é a LeNet. Ela é a primeira CNN bem sucedida da história, [proposta em 1998 pelo Yann LeCun](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf). \n",
    "\n",
    "<img src=\"Lenet1.png\" width=\"800\">\n",
    "\n",
    "<img src=\"Lenet2.jpeg\" width=\"700\">\n",
    "\n",
    "Vamos implementar blocos convolucionais incluindo todas as camadas que aprendemos nesse curso:\n",
    "```python\n",
    "net = nn.Sequential(\n",
    "          nn.Conv2d(...),\n",
    "          nn.BatchNorm2d(...),\n",
    "          nn.Tanh(), # Ativação específica da LeNet\n",
    "          nn.AvgPool2d(...), # Pooling específico da LeNet\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yx8rF8UB29Az"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Tanh()\n",
      "  (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): Tanh()\n",
      "  (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (8): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (9): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): Tanh()\n",
      "  (11): Flatten(start_dim=1, end_dim=-1)\n",
      "  (12): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (13): Tanh()\n",
      "  (14): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a rede no estilo LeNet-5 usando um contêiner sequencial.\n",
    "net = nn.Sequential(\n",
    "# Bloco conv 1: 3 canais → 6 mapas, kernel 5, sem padding (32→28).\n",
    "        nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),        # entrada: (b, 3, 32, 32) e saida: (b, 6, 28, 28)\n",
    "# Normaliza por canal (estabiliza treinamento).\n",
    "        nn.BatchNorm2d(6),\n",
    "# Ativação Tanh (seguindo o LeNet original).\n",
    "        nn.Tanh(),\n",
    "# Pooling médio 2×2 (reduz 28→14 em H e W).\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2, padding=0),           # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n",
    "        \n",
    "# Bloco conv 2: 6→16 mapas, kernel 5, sem padding (14→10).\n",
    "        nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),       # entrada: (b, 6, 14, 14) e saida: (b, 16, 10, 10)\n",
    "# BN para os 16 canais.\n",
    "        nn.BatchNorm2d(16),\n",
    "# Ativação Tanh.\n",
    "        nn.Tanh(),\n",
    "# Pooling médio 2×2 (10→5).\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2, padding=0),           # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n",
    "        \n",
    "# Bloco conv 3: 16→120 mapas, kernel 5 cobrindo todo o 5×5 (5→1).\n",
    "        nn.Conv2d(16, 120, kernel_size=5, stride=1, padding=0),     # entrada: (b, 16, 5, 5) e saida: (b, 120, 1, 1)\n",
    "# BN para 120 canais.\n",
    "        nn.BatchNorm2d(120),\n",
    "# Ativação Tanh.\n",
    "        nn.Tanh(),\n",
    "# Achata o tensor (b,120,1,1) → (b,120).\n",
    "        nn.Flatten(),  # lineariza formando um vetor                # entrada: (b, 120, 1, 1) e saida: (b, 120*1*1) = (b, 120)\n",
    "        \n",
    "# Camada totalmente conectada: 120→84.\n",
    "        nn.Linear(120, 84),                                         # entrada: (b, 120) e saida: (b, 84)\n",
    "# Tanh novamente (padrão LeNet).\n",
    "        nn.Tanh(),\n",
    "# Camada de saída: 84→10 classes (CIFAR-10).\n",
    "        nn.Linear(84, 10),                                          # entrada: (b, 84) e saida: (b, 10)\n",
    "        )\n",
    "\n",
    "# Move o modelo para o dispositivo configurado (GPU se disponível, senão CPU).\n",
    "net = net.to(args['device'])\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d5a15",
   "metadata": {
    "name": "hyper_override"
   },
   "outputs": [],
   "source": [
    "# >>> Hiperparâmetros e otimizador/scheduler (override recomendado)\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# Loss com label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "\n",
    "# Otimizador (SGD + momentum + weight decay)\n",
    "try:\n",
    "    optimizer = torch.optim.SGD(\n",
    "        net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True\n",
    "    )\n",
    "    print(\"Optimizer: SGD(lr=0.1, momentum=0.9, wd=5e-4, nesterov=True)\")\n",
    "except NameError as e:\n",
    "    print(\"Atenção: modelo 'net' ainda não definido ao rodar esta célula. Execute após criar o modelo.\")\n",
    "    \n",
    "# Scheduler (Cosine Annealing). Usa args['epoch_num'] se existir, senão T_max=80.\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "TMAX = None\n",
    "try:\n",
    "    TMAX = int(args.get('epoch_num', 80))\n",
    "except Exception:\n",
    "    TMAX = 80\n",
    "\n",
    "try:\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=TMAX, eta_min=1e-4)\n",
    "    print(f\"Scheduler: CosineAnnealingLR(T_max={TMAX}, eta_min=1e-4)\")\n",
    "except Exception as e:\n",
    "    print(\"Falha ao criar scheduler Cosine. Mantenha o atual ou crie após definir optimizer/net.\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsxmosWjUo9f"
   },
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDpRre0gUn-Q"
   },
   "outputs": [],
   "source": [
    "# # Definindo a rede\n",
    "# net = nn.Sequential(\n",
    "#         ## ConvBlock 1\n",
    "#         nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),      # entrada: (b, 3, 224, 224) e saida: (b, 64, 224, 224)\n",
    "#         nn.ReLU(),\n",
    "#         nn.MaxPool2d(kernel_size=2, stride=2, padding=0),          # entrada: (b, 64, 224, 224) e saida: (b, 64, 112, 112)\n",
    "        \n",
    "#         ## ConvBlock 2\n",
    "#         nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),    # entrada: (b, 64, 112, 112) e saida: (b, 128, 112, 112)\n",
    "#         nn.ReLU(),\n",
    "#         nn.MaxPool2d(kernel_size=2, stride=2, padding=0),          # entrada: (b, 128, 112, 112) e saida: (b, 128, 56, 56)\n",
    "        \n",
    "#         ## ConvBlock 3\n",
    "#         nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),   # entrada: (b, 128, 56, 56) e saida: (b, 256, 56, 56)\n",
    "#         nn.ReLU(),\n",
    "#         nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),   # entrada: (b, 256, 56, 56) e saida: (b, 256, 56, 56)\n",
    "#         nn.ReLU(),\n",
    "#         nn.MaxPool2d(kernel_size=2, stride=2, padding=0),          # entrada: (b, 256, 56, 56) e saida: (b, 256, 28, 28)\n",
    "        \n",
    "#         ## ConvBlock 4\n",
    "#         nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),   # entrada: (b, 256, 28, 28) e saida: (b, 512, 28, 28)\n",
    "#         nn.ReLU(),\n",
    "#         nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),   # entrada: (b, 512, 28, 28) e saida: (b, 512, 28, 28)\n",
    "#         nn.ReLU(),\n",
    "#         nn.MaxPool2d(kernel_size=2, stride=2, padding=0),          # entrada: (b, 512, 28, 28) e saida: (b, 512, 14, 14)\n",
    "        \n",
    "#         ## ConvBlock 4\n",
    "#         nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),   # entrada: (b, 512, 14, 14) e saida: (b, 512, 14, 14)\n",
    "#         nn.ReLU(),\n",
    "#         nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),   # entrada: (b, 512, 14, 14) e saida: (b, 512, 14, 14)\n",
    "#         nn.ReLU(),\n",
    "#         nn.MaxPool2d(kernel_size=2, stride=2, padding=0),          # entrada: (b, 512, 14, 14) e saida: (b, 512, 7, 7)\n",
    "#         nn.Flatten(),  # lineariza formando um vetor               # entrada: (b, 512, 7, 7) e saida: (b, 512*7*7) = (b, 25088)\n",
    " \n",
    "#         ## DenseBlock\n",
    "#         nn.Linear(25088, 4096),                                    # entrada: (b, 25088) e saida: (b, 4096)\n",
    "#         nn.ReLU(),\n",
    "#         nn.Linear(4096, 4096),                                     # entrada: (b, 4096) e saida: (b, 4096)\n",
    "#         nn.ReLU(),\n",
    "#         nn.Linear(4096, 10),                                       # entrada: (b, 4096) e saida: (b, 10)\n",
    "#         nn.Softmax(dim=-1)\n",
    "#         )\n",
    "\n",
    "# # Subindo no hardware de GPU (se disponível)\n",
    "# net = net.to(args['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_mcMxEiGdWO"
   },
   "source": [
    "# Estratégias de Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEf-DBaVPHGi"
   },
   "source": [
    "## Do zero (From scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-XdWeUXx1Im"
   },
   "source": [
    "O primeiro passo do treinamento do zero é definir os algoritmos que serão utilizados no processo de treinamento. Eles são:\n",
    "\n",
    "* **Função de perda**, que vai avaliar a qualidade da performance da rede a cada passo de treinamento;\n",
    "* **Otimizador**, que a partir da função de perda vai definir a melhor forma de atualizar os pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pInOWfvTIPBl"
   },
   "outputs": [],
   "source": [
    "# Define a função de perda de entropia cruzada (adequada para classificação multi-classe) e move-a para o device (CPU/GPU).\n",
    "criterion = nn.CrossEntropyLoss().to(args['device'])\n",
    "\n",
    "# Cria o otimizador Adam para todos os parâmetros da rede, usando a taxa de aprendizado e o weight decay definidos em args.\n",
    "optimizer = optim.Adam(net.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "# Controla a redução da taxa de aprendizado quando a perda de validação estagna.\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdKiVlR_xzCk"
   },
   "source": [
    "Relembrando o passo a passo do fluxo de treinamento:\n",
    "\n",
    "* Iterar nas épocas\n",
    "* Iterar nos batches\n",
    "* Cast dos dados no dispositivo de hardware\n",
    "* Forward na rede e cálculo da loss\n",
    "* Zerar o gradiente do otimizador\n",
    "* Cálculo do gradiente e atualização dos pesos\n",
    "\n",
    "Para acompanhar a convergência do seu modelo (e garantir que tudo foi feito certinho), ao final de cada época podemos imprimir a média e o desvio padrão das perdas de cada iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stZS9TSSGdC-"
   },
   "outputs": [],
   "source": [
    "# Define a função de treinamento que executa uma época completa sobre o DataLoader de treino.\n",
    "def train(train_loader, net, epoch):\n",
    "\n",
    "  # Coloca a rede em modo de treino (ativa Dropout, atualiza as estatísticas do BatchNorm).\n",
    "  net.train()\n",
    "  \n",
    "  # Marca o início para medir o tempo gasto na época.\n",
    "  start = time.time()\n",
    "  \n",
    "  # Acumuladores: lista de perdas por lote e vetores de previsões/rótulos para calcular acurácia.\n",
    "  epoch_loss  = []\n",
    "  pred_list, rotulo_list = [], []\n",
    "  # Loop sobre os lotes (mini-batches) do conjunto de treino.\n",
    "  for batch in train_loader:\n",
    "    \n",
    "    # Desempacota o lote em tensores de entrada (dado) e rótulos (rotulo).\n",
    "    dado, rotulo = batch\n",
    "    \n",
    "    # Move dados e rótulos para o dispositivo (GPU/CPU) configurado.\n",
    "    dado = dado.to(args['device'])\n",
    "    rotulo = rotulo.to(args['device'])\n",
    "    \n",
    "    # Passagem direta: obtém logits (pontuações antes do softmax) para cada classe.\n",
    "    ypred = net(dado)\n",
    "    # Calcula a perda de entropia cruzada entre os logits e os rótulos verdadeiros.\n",
    "    loss = criterion(ypred, rotulo)\n",
    "    # Armazena a perda do lote (nota: .item() seria equivalente para obter um escalar em Python).\n",
    "    epoch_loss.append(loss.cpu().data)\n",
    "\n",
    "    # Extrai as classes previstas via argmax ao longo do eixo das classes.\n",
    "    _, pred = torch.max(ypred, axis=1)\n",
    "    # Guarda as predições no CPU como NumPy para métricas.\n",
    "    pred_list.append(pred.cpu().numpy())\n",
    "    # Guarda os rótulos verdadeiros no CPU como NumPy.\n",
    "    rotulo_list.append(rotulo.cpu().numpy())\n",
    "    \n",
    "    # Zera gradientes acumulados do passo anterior.\n",
    "    optimizer.zero_grad()\n",
    "    # Backprop: propaga o erro para calcular gradientes.\n",
    "    loss.backward()\n",
    "    # Atualiza os parâmetros conforme a regra do otimizador.\n",
    "    optimizer.step()\n",
    "   \n",
    "  # Converte a lista de perdas para array NumPy (facilita média e desvio).\n",
    "  epoch_loss = np.asarray(epoch_loss)\n",
    "  # Achata as listas de predições e rótulos para vetores 1D alinhados.\n",
    "  pred_list  = np.asarray(pred_list).ravel()\n",
    "  rotulo_list  = np.asarray(rotulo_list).ravel()\n",
    "\n",
    "  # Calcula a acurácia da época.\n",
    "  acc = accuracy_score(rotulo_list, pred_list)\n",
    "  \n",
    "  # Marca o fim e calcula o tempo total da época.\n",
    "  end = time.time()\n",
    "  # Imprime um resumo legível da época: perda média, desvio-padrão, acurácia (%) e tempo.\n",
    "  print('#################### Train ####################')\n",
    "  print('Epoch %d, Loss: %.4f +/- %.4f, Acc: %.2f, Time: %.2f' % (epoch, epoch_loss.mean(), epoch_loss.std(), acc*100, end-start))\n",
    "  \n",
    "  # Retorna a perda média da época (útil para plotar curva de treino).\n",
    "  return epoch_loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DHMGMlSP2Gg2"
   },
   "source": [
    "### Validação\n",
    "\n",
    "Para essa etapa, o PyTorch oferece dois artifícios:\n",
    "* ```model.eval()```: Impacta no *forward* da rede, informando as camadas caso seu comportamento mude entre fluxos (ex: dropout).\n",
    "* ```with torch.no_grad()```: Gerenciador de contexto que desabilita o cálculo e armazenamento de gradientes (economia de tempo e memória). Todo o código de validação deve ser executado dentro desse contexto.\n",
    "\n",
    "Exemplo de código para validação\n",
    "\n",
    "```python\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in test_loader:\n",
    "      # Código de validação\n",
    "```\n",
    "\n",
    "Existe o equivalente ao ```model.eval()``` para explicitar que a sua rede deve estar em modo de treino, é o ```model.train()```. Apesar de ser o padrão dos modelos, é boa prática definir também o modo de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxbiYRdXG90z"
   },
   "outputs": [],
   "source": [
    "# Define a função de validação que roda a avaliação do modelo por uma época.\n",
    "def validate(test_loader, net, epoch):\n",
    "\n",
    "  # Coloca o modelo em modo de avaliação (desativa Dropout e usa BN com estatísticas fixas).\n",
    "  # Evaluation mode\n",
    "  net.eval()\n",
    "  \n",
    "  # Inicia a contagem de tempo desta fase de validação.\n",
    "  start = time.time()\n",
    "  \n",
    "  # Vetores para acumular perdas por lote e listas de predições/rótulos.\n",
    "  epoch_loss  = []\n",
    "  pred_list, rotulo_list = [], []\n",
    "  # Desativa o cálculo de gradientes para acelerar e economizar memória.\n",
    "  with torch.no_grad(): \n",
    "    # Itera pelos lotes do DataLoader de teste/validação.\n",
    "    for batch in test_loader:\n",
    "\n",
    "      # Desempacota o lote em tensores de entrada (imagens) e rótulos verdadeiros.\n",
    "      dado, rotulo = batch\n",
    "\n",
    "      # Move os dados para o dispositivo (GPU/CPU) configurado em args['device'].\n",
    "      # Cast do dado na GPU\n",
    "      dado = dado.to(args['device'])\n",
    "      # Move os rótulos para o mesmo dispositivo.\n",
    "      rotulo = rotulo.to(args['device'])\n",
    "\n",
    "      # Passagem direta (forward) para obter os logits preditos.\n",
    "      # Forward\n",
    "      ypred = net(dado)\n",
    "      # Calcula a perda de entropia cruzada entre logits e rótulos.\n",
    "      loss = criterion(ypred, rotulo)\n",
    "      # Guarda a perda do lote (nota: .item() seria uma alternativa direta ao escalar).\n",
    "      epoch_loss.append(loss.cpu().data)\n",
    "\n",
    "      # Obtém as classes previstas via argmax no eixo das classes.\n",
    "      _, pred = torch.max(ypred, axis=1)\n",
    "      # Acumula as predições no CPU como arrays NumPy para cálculo de métricas depois.\n",
    "      pred_list.append(pred.cpu().numpy())\n",
    "      # Acumula os rótulos verdadeiros.\n",
    "      rotulo_list.append(rotulo.cpu().numpy())\n",
    "\n",
    "  # Converte a lista de perdas em array NumPy para facilitar média e desvio.\n",
    "  epoch_loss = np.asarray(epoch_loss)\n",
    "  # Achata as listas de predições (N_lotes × batch → N_amostras).\n",
    "  pred_list  = np.asarray(pred_list).ravel()\n",
    "  # Achata as listas de rótulos (N_lotes × batch → N_amostras).\n",
    "  rotulo_list  = np.asarray(rotulo_list).ravel()\n",
    "\n",
    "  # Calcula a acurácia;\n",
    "  acc = accuracy_score(rotulo_list, pred_list)\n",
    "  \n",
    "  # Finaliza a contagem de tempo desta fase.\n",
    "  end = time.time()\n",
    "  # Cabeçalho para separar os logs de validação no console.\n",
    "  print('********** Validate **********')\n",
    "  # Imprime resumo: época, perda média, desvio padrão, acurácia (%) e tempo decorrido.\n",
    "  print('Epoch %d, Loss: %.4f +/- %.4f, Acc: %.2f, Time: %.2f\\n' % (epoch, epoch_loss.mean(), epoch_loss.std(), acc*100, end-start))\n",
    "  \n",
    "  # Retorna a perda média da época de validação (útil para monitorar curvas).\n",
    "  return epoch_loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d114110",
   "metadata": {},
   "source": [
    "### Monitoramento das losses por época\n",
    "\n",
    "Executamos o ciclo completo de treinamento e validação, armazenando a loss média de cada época em `train_losses` e `test_losses`. Essas listas serão usadas logo abaixo para visualizar a evolução do aprendizado do modelo e interpretar os resultados finais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "l5L-NPIC8hk0",
    "outputId": "a44a3891-2cff-4822-d531-1d51cc0e3fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Train ####################\n",
      "Epoch 0, Loss: 1.7208 +/- 0.1678, Acc: 38.39, Time: 25.69\n",
      "********** Validate **********\n",
      "Epoch 0, Loss: 1.5367 +/- 0.1239, Acc: 44.81, Time: 2.07\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 1, Loss: 1.5497 +/- 0.1355, Acc: 43.81, Time: 25.28\n",
      "********** Validate **********\n",
      "Epoch 1, Loss: 1.4545 +/- 0.1168, Acc: 47.71, Time: 2.12\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 2, Loss: 1.4903 +/- 0.1320, Acc: 45.96, Time: 26.65\n",
      "********** Validate **********\n",
      "Epoch 2, Loss: 1.4103 +/- 0.1379, Acc: 48.30, Time: 2.08\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 3, Loss: 1.4584 +/- 0.1329, Acc: 47.24, Time: 27.20\n",
      "********** Validate **********\n",
      "Epoch 3, Loss: 1.3729 +/- 0.1204, Acc: 50.97, Time: 2.14\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 4, Loss: 1.4286 +/- 0.1402, Acc: 48.32, Time: 27.14\n",
      "********** Validate **********\n",
      "Epoch 4, Loss: 1.3613 +/- 0.1355, Acc: 50.99, Time: 2.06\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 5, Loss: 1.3913 +/- 0.1371, Acc: 49.97, Time: 25.51\n",
      "********** Validate **********\n",
      "Epoch 5, Loss: 1.3493 +/- 0.1328, Acc: 51.51, Time: 2.10\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 6, Loss: 1.3758 +/- 0.1394, Acc: 50.76, Time: 26.70\n",
      "********** Validate **********\n",
      "Epoch 6, Loss: 1.3103 +/- 0.1371, Acc: 53.12, Time: 2.61\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 7, Loss: 1.3421 +/- 0.1406, Acc: 52.13, Time: 26.02\n",
      "********** Validate **********\n",
      "Epoch 7, Loss: 1.2597 +/- 0.1485, Acc: 55.19, Time: 2.04\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 8, Loss: 1.3160 +/- 0.1455, Acc: 53.37, Time: 26.15\n",
      "********** Validate **********\n",
      "Epoch 8, Loss: 1.2835 +/- 0.1438, Acc: 55.02, Time: 2.54\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 9, Loss: 1.2965 +/- 0.1438, Acc: 54.13, Time: 27.44\n",
      "********** Validate **********\n",
      "Epoch 9, Loss: 1.2739 +/- 0.1439, Acc: 54.71, Time: 2.05\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 10, Loss: 1.2805 +/- 0.1420, Acc: 54.98, Time: 28.11\n",
      "********** Validate **********\n",
      "Epoch 10, Loss: 1.3822 +/- 0.1455, Acc: 50.83, Time: 2.32\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 11, Loss: 1.2693 +/- 0.1471, Acc: 55.36, Time: 31.44\n",
      "********** Validate **********\n",
      "Epoch 11, Loss: 1.2194 +/- 0.1440, Acc: 56.60, Time: 3.08\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 12, Loss: 1.2575 +/- 0.1395, Acc: 55.60, Time: 29.05\n",
      "********** Validate **********\n",
      "Epoch 12, Loss: 1.3440 +/- 0.1378, Acc: 52.52, Time: 2.14\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 13, Loss: 1.2513 +/- 0.1425, Acc: 55.96, Time: 27.66\n",
      "********** Validate **********\n",
      "Epoch 13, Loss: 1.2623 +/- 0.1494, Acc: 54.60, Time: 2.33\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 14, Loss: 1.2489 +/- 0.1444, Acc: 55.88, Time: 27.08\n",
      "********** Validate **********\n",
      "Epoch 14, Loss: 1.2196 +/- 0.1264, Acc: 57.36, Time: 2.18\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 15, Loss: 1.2386 +/- 0.1395, Acc: 56.53, Time: 26.15\n",
      "********** Validate **********\n",
      "Epoch 15, Loss: 1.2188 +/- 0.1388, Acc: 57.03, Time: 2.23\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 16, Loss: 1.2353 +/- 0.1399, Acc: 56.60, Time: 26.26\n",
      "********** Validate **********\n",
      "Epoch 16, Loss: 1.2094 +/- 0.1374, Acc: 57.30, Time: 2.00\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 17, Loss: 1.2353 +/- 0.1468, Acc: 56.65, Time: 26.48\n",
      "********** Validate **********\n",
      "Epoch 17, Loss: 1.1805 +/- 0.1369, Acc: 58.74, Time: 2.11\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 18, Loss: 1.2267 +/- 0.1430, Acc: 56.95, Time: 27.24\n",
      "********** Validate **********\n",
      "Epoch 18, Loss: 1.2428 +/- 0.1405, Acc: 55.95, Time: 2.19\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 19, Loss: 1.2241 +/- 0.1409, Acc: 56.97, Time: 28.05\n",
      "********** Validate **********\n",
      "Epoch 19, Loss: 1.1557 +/- 0.1313, Acc: 59.68, Time: 2.05\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 20, Loss: 1.2162 +/- 0.1496, Acc: 57.24, Time: 26.06\n",
      "********** Validate **********\n",
      "Epoch 20, Loss: 1.2124 +/- 0.1589, Acc: 56.56, Time: 2.20\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 21, Loss: 1.2165 +/- 0.1397, Acc: 57.24, Time: 25.76\n",
      "********** Validate **********\n",
      "Epoch 21, Loss: 1.1946 +/- 0.1491, Acc: 57.68, Time: 2.29\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 22, Loss: 1.2158 +/- 0.1478, Acc: 57.50, Time: 25.68\n",
      "********** Validate **********\n",
      "Epoch 22, Loss: 1.1716 +/- 0.1514, Acc: 58.74, Time: 2.03\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 23, Loss: 1.2120 +/- 0.1396, Acc: 57.66, Time: 25.39\n",
      "********** Validate **********\n",
      "Epoch 23, Loss: 1.2547 +/- 0.1348, Acc: 54.49, Time: 2.19\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 24, Loss: 1.1663 +/- 0.1406, Acc: 59.28, Time: 26.13\n",
      "********** Validate **********\n",
      "Epoch 24, Loss: 1.1462 +/- 0.1527, Acc: 59.67, Time: 2.51\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 25, Loss: 1.1608 +/- 0.1439, Acc: 59.41, Time: 27.47\n",
      "********** Validate **********\n",
      "Epoch 25, Loss: 1.1545 +/- 0.1510, Acc: 59.31, Time: 2.29\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 26, Loss: 1.1559 +/- 0.1419, Acc: 59.63, Time: 26.05\n",
      "********** Validate **********\n",
      "Epoch 26, Loss: 1.1250 +/- 0.1502, Acc: 60.23, Time: 2.11\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 27, Loss: 1.1549 +/- 0.1422, Acc: 59.46, Time: 26.85\n",
      "********** Validate **********\n",
      "Epoch 27, Loss: 1.1298 +/- 0.1356, Acc: 60.95, Time: 2.17\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 28, Loss: 1.1483 +/- 0.1438, Acc: 59.77, Time: 26.67\n",
      "********** Validate **********\n",
      "Epoch 28, Loss: 1.1013 +/- 0.1321, Acc: 61.52, Time: 2.21\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 29, Loss: 1.1520 +/- 0.1489, Acc: 59.67, Time: 26.19\n",
      "********** Validate **********\n",
      "Epoch 29, Loss: 1.0889 +/- 0.1568, Acc: 61.80, Time: 2.09\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 30, Loss: 1.1472 +/- 0.1452, Acc: 59.90, Time: 25.85\n",
      "********** Validate **********\n",
      "Epoch 30, Loss: 1.1278 +/- 0.1607, Acc: 60.94, Time: 2.02\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 31, Loss: 1.1450 +/- 0.1443, Acc: 59.77, Time: 27.27\n",
      "********** Validate **********\n",
      "Epoch 31, Loss: 1.1378 +/- 0.1429, Acc: 60.96, Time: 2.08\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 32, Loss: 1.1397 +/- 0.1467, Acc: 60.30, Time: 26.56\n",
      "********** Validate **********\n",
      "Epoch 32, Loss: 1.1361 +/- 0.1394, Acc: 59.99, Time: 2.12\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 33, Loss: 1.1315 +/- 0.1452, Acc: 60.36, Time: 30.46\n",
      "********** Validate **********\n",
      "Epoch 33, Loss: 1.0965 +/- 0.1381, Acc: 62.06, Time: 2.10\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 34, Loss: 1.1054 +/- 0.1411, Acc: 61.42, Time: 26.11\n",
      "********** Validate **********\n",
      "Epoch 34, Loss: 1.0505 +/- 0.1303, Acc: 63.57, Time: 2.14\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 35, Loss: 1.0949 +/- 0.1398, Acc: 61.71, Time: 26.60\n",
      "********** Validate **********\n",
      "Epoch 35, Loss: 1.0668 +/- 0.1461, Acc: 62.71, Time: 2.08\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 36, Loss: 1.0871 +/- 0.1368, Acc: 62.15, Time: 25.82\n",
      "********** Validate **********\n",
      "Epoch 36, Loss: 1.0322 +/- 0.1421, Acc: 64.09, Time: 2.17\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 37, Loss: 1.0874 +/- 0.1399, Acc: 61.88, Time: 26.81\n",
      "********** Validate **********\n",
      "Epoch 37, Loss: 1.0598 +/- 0.1505, Acc: 62.96, Time: 2.02\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 38, Loss: 1.0842 +/- 0.1405, Acc: 62.24, Time: 25.82\n",
      "********** Validate **********\n",
      "Epoch 38, Loss: 1.0431 +/- 0.1411, Acc: 63.51, Time: 2.08\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 39, Loss: 1.0852 +/- 0.1459, Acc: 62.27, Time: 25.77\n",
      "********** Validate **********\n",
      "Epoch 39, Loss: 1.0531 +/- 0.1408, Acc: 63.38, Time: 2.27\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 40, Loss: 1.0769 +/- 0.1357, Acc: 62.58, Time: 25.38\n",
      "********** Validate **********\n",
      "Epoch 40, Loss: 1.1030 +/- 0.1484, Acc: 61.28, Time: 2.03\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 41, Loss: 1.0581 +/- 0.1361, Acc: 63.13, Time: 26.47\n",
      "********** Validate **********\n",
      "Epoch 41, Loss: 1.0111 +/- 0.1448, Acc: 65.01, Time: 2.16\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 42, Loss: 1.0532 +/- 0.1362, Acc: 63.32, Time: 28.46\n",
      "********** Validate **********\n",
      "Epoch 42, Loss: 1.0117 +/- 0.1526, Acc: 65.04, Time: 2.33\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 43, Loss: 1.0530 +/- 0.1415, Acc: 63.46, Time: 27.84\n",
      "********** Validate **********\n",
      "Epoch 43, Loss: 1.0107 +/- 0.1475, Acc: 65.04, Time: 2.06\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 44, Loss: 1.0510 +/- 0.1423, Acc: 63.47, Time: 27.27\n",
      "********** Validate **********\n",
      "Epoch 44, Loss: 1.0088 +/- 0.1349, Acc: 65.34, Time: 2.21\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 45, Loss: 1.0522 +/- 0.1433, Acc: 63.39, Time: 26.83\n",
      "********** Validate **********\n",
      "Epoch 45, Loss: 0.9959 +/- 0.1418, Acc: 65.77, Time: 2.05\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 46, Loss: 1.0551 +/- 0.1524, Acc: 63.46, Time: 26.61\n",
      "********** Validate **********\n",
      "Epoch 46, Loss: 1.0026 +/- 0.1461, Acc: 64.95, Time: 2.13\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 47, Loss: 1.0491 +/- 0.1450, Acc: 63.42, Time: 26.13\n",
      "********** Validate **********\n",
      "Epoch 47, Loss: 0.9987 +/- 0.1304, Acc: 65.49, Time: 2.13\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 48, Loss: 1.0473 +/- 0.1454, Acc: 63.46, Time: 26.39\n",
      "********** Validate **********\n",
      "Epoch 48, Loss: 1.0122 +/- 0.1391, Acc: 64.91, Time: 2.17\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 49, Loss: 1.0469 +/- 0.1460, Acc: 63.70, Time: 25.93\n",
      "********** Validate **********\n",
      "Epoch 49, Loss: 0.9980 +/- 0.1274, Acc: 65.64, Time: 2.12\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 50, Loss: 1.0437 +/- 0.1403, Acc: 63.77, Time: 25.90\n",
      "********** Validate **********\n",
      "Epoch 50, Loss: 0.9919 +/- 0.1485, Acc: 65.74, Time: 2.06\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 51, Loss: 1.0361 +/- 0.1467, Acc: 64.08, Time: 28.58\n",
      "********** Validate **********\n",
      "Epoch 51, Loss: 0.9812 +/- 0.1253, Acc: 66.23, Time: 2.38\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 52, Loss: 1.0343 +/- 0.1404, Acc: 63.93, Time: 31.98\n",
      "********** Validate **********\n",
      "Epoch 52, Loss: 0.9847 +/- 0.1448, Acc: 66.13, Time: 2.70\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 53, Loss: 1.0322 +/- 0.1375, Acc: 64.17, Time: 32.84\n",
      "********** Validate **********\n",
      "Epoch 53, Loss: 0.9810 +/- 0.1406, Acc: 66.43, Time: 2.74\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 54, Loss: 1.0322 +/- 0.1462, Acc: 64.26, Time: 32.01\n",
      "********** Validate **********\n",
      "Epoch 54, Loss: 0.9960 +/- 0.1481, Acc: 65.61, Time: 2.64\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 55, Loss: 1.0273 +/- 0.1399, Acc: 64.30, Time: 32.72\n",
      "********** Validate **********\n",
      "Epoch 55, Loss: 0.9801 +/- 0.1343, Acc: 66.30, Time: 2.62\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 56, Loss: 1.0291 +/- 0.1407, Acc: 64.33, Time: 31.23\n",
      "********** Validate **********\n",
      "Epoch 56, Loss: 0.9809 +/- 0.1395, Acc: 66.43, Time: 2.50\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 57, Loss: 1.0272 +/- 0.1464, Acc: 64.52, Time: 31.25\n",
      "********** Validate **********\n",
      "Epoch 57, Loss: 0.9885 +/- 0.1428, Acc: 65.79, Time: 2.58\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 58, Loss: 1.0291 +/- 0.1487, Acc: 64.24, Time: 30.40\n",
      "********** Validate **********\n",
      "Epoch 58, Loss: 0.9858 +/- 0.1497, Acc: 66.14, Time: 2.47\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 59, Loss: 1.0268 +/- 0.1470, Acc: 64.33, Time: 31.55\n",
      "********** Validate **********\n",
      "Epoch 59, Loss: 0.9814 +/- 0.1384, Acc: 66.17, Time: 2.31\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 60, Loss: 1.0259 +/- 0.1454, Acc: 64.61, Time: 29.09\n",
      "********** Validate **********\n",
      "Epoch 60, Loss: 0.9753 +/- 0.1279, Acc: 66.77, Time: 2.56\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 61, Loss: 1.0241 +/- 0.1448, Acc: 64.42, Time: 33.00\n",
      "********** Validate **********\n",
      "Epoch 61, Loss: 0.9813 +/- 0.1482, Acc: 66.33, Time: 2.75\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 62, Loss: 1.0198 +/- 0.1461, Acc: 64.53, Time: 38.25\n",
      "********** Validate **********\n",
      "Epoch 62, Loss: 0.9717 +/- 0.1383, Acc: 66.93, Time: 2.78\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 63, Loss: 1.0189 +/- 0.1432, Acc: 64.56, Time: 32.14\n",
      "********** Validate **********\n",
      "Epoch 63, Loss: 0.9726 +/- 0.1445, Acc: 66.85, Time: 2.93\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 64, Loss: 1.0181 +/- 0.1422, Acc: 64.84, Time: 32.92\n",
      "********** Validate **********\n",
      "Epoch 64, Loss: 0.9691 +/- 0.1357, Acc: 67.09, Time: 2.66\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 65, Loss: 1.0218 +/- 0.1372, Acc: 64.41, Time: 33.48\n",
      "********** Validate **********\n",
      "Epoch 65, Loss: 0.9721 +/- 0.1395, Acc: 66.74, Time: 2.65\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 66, Loss: 1.0187 +/- 0.1413, Acc: 64.55, Time: 32.91\n",
      "********** Validate **********\n",
      "Epoch 66, Loss: 0.9719 +/- 0.1404, Acc: 66.57, Time: 2.62\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 67, Loss: 1.0153 +/- 0.1408, Acc: 64.74, Time: 32.66\n",
      "********** Validate **********\n",
      "Epoch 67, Loss: 0.9797 +/- 0.1425, Acc: 66.42, Time: 2.69\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 68, Loss: 1.0172 +/- 0.1405, Acc: 64.69, Time: 31.65\n",
      "********** Validate **********\n",
      "Epoch 68, Loss: 0.9698 +/- 0.1305, Acc: 66.91, Time: 2.75\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 69, Loss: 1.0172 +/- 0.1396, Acc: 64.53, Time: 30.98\n",
      "********** Validate **********\n",
      "Epoch 69, Loss: 0.9683 +/- 0.1377, Acc: 66.88, Time: 2.65\n",
      "\n",
      "#################### Train ####################\n",
      "Epoch 70, Loss: 1.0149 +/- 0.1395, Acc: 64.77, Time: 30.95\n",
      "********** Validate **********\n",
      "Epoch 70, Loss: 0.9698 +/- 0.1338, Acc: 66.68, Time: 2.83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# >>> Loop de treino com checkpoint, early stopping, EMA e scheduler compatível\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience = 12\n",
    "bad_epochs = 0\n",
    "\n",
    "for epoch in range(args['epoch_num']):\n",
    "    # ---- Treino ----\n",
    "    train_loss = train(train_loader, net, epoch)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Atualiza EMA após treinamento (assumindo que train() faz optimizer.step() internamente)\n",
    "    if 'ema_net' in globals() and use_ema:\n",
    "        with torch.no_grad():\n",
    "            for p, p_ema in zip(net.parameters(), ema_net.parameters()):\n",
    "                p_ema.data.mul_(ema_decay).add_(p.data, alpha=1-ema_decay)\n",
    "\n",
    "    # ---- Validação (avaliar no EMA se disponível) ----\n",
    "    _val_loss = validate(test_loader, net, epoch)  # mantém saída/prints originais\n",
    "    test_losses.append(_val_loss)\n",
    "\n",
    "    model_for_eval = ema_net if ('ema_net' in globals() and use_ema) else net\n",
    "    val_loss_eval, val_acc_eval = eval_loss_acc(model_for_eval, test_loader, criterion, args['device'])\n",
    "\n",
    "    # ---- Checkpoint do melhor (por val_loss) ----\n",
    "    improved = val_loss_eval < (best_loss - 1e-4)\n",
    "    if improved:\n",
    "        best_loss = val_loss_eval\n",
    "        bad_epochs = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_for_eval.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss_eval,\n",
    "            'val_acc': val_acc_eval,\n",
    "        }, 'best_model.pt')\n",
    "        print(f\"✔️  Novo melhor modelo salvo (epoch {epoch}) | val_loss={val_loss_eval:.4f} | val_acc={val_acc_eval:.2f}%\")\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "\n",
    "    # ---- Scheduler step (compatível) ----\n",
    "    try:\n",
    "        from torch.optim.lr_scheduler import ReduceLROnPlateau as _Reduce\n",
    "        if isinstance(scheduler, _Reduce):\n",
    "            scheduler.step(val_loss_eval)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "    except Exception as e:\n",
    "        pass  # caso não haja scheduler\n",
    "\n",
    "    # ---- Early Stopping ----\n",
    "    if bad_epochs >= patience:\n",
    "        print(f\"⏹️ Early stopping em epoch {epoch} (sem melhora em {patience} épocas). Melhor val_loss={best_loss:.4f}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0a77c",
   "metadata": {},
   "source": [
    "### Curvas de perda\n",
    "\n",
    "Com as listas `train_losses` e `test_losses` preenchidas, o gráfico abaixo compara a perda média por época em treino e validação, ajudando a diagnosticar overfitting, underfitting ou convergência adequada do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d620d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma figura 8×5 para os gráficos.\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plota a curva da loss de treino ao longo das épocas (1..N), marcando os pontos.\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Treino', marker='o')\n",
    "\n",
    "# Plota a curva da loss de validação ao longo das épocas, também com marcadores.\n",
    "plt.plot(range(1, len(test_losses) + 1), test_losses, label='Validação', marker='o')\n",
    "\n",
    "# Define o título do gráfico.\n",
    "plt.title('Evolução da loss por época')\n",
    "\n",
    "# Rotula o eixo X com “Época”.\n",
    "plt.xlabel('Época')\n",
    "\n",
    "# Rotula o eixo Y com “Loss média”.\n",
    "plt.ylabel('Loss média')\n",
    "\n",
    "# Adiciona uma grade discreta para facilitar a leitura.\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Exibe a legenda para distinguir as curvas.\n",
    "plt.legend()\n",
    "\n",
    "# Ajusta os espaçamentos para evitar cortes de textos/elementos.\n",
    "plt.tight_layout()\n",
    "\n",
    "# Renderiza o gráfico na saída.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0e171",
   "metadata": {},
   "source": [
    "### Avaliação final no conjunto de teste\n",
    "\n",
    "Após o treinamento, avaliamos o modelo utilizando todos os exemplos de teste. Serão exibidos o relatório de classificação (precisão, recall e F1 por classe) e a matriz de confusão, que evidencia em um mapa de calor onde o modelo acerta ou confunde as classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabeçalho informativo desta seção (aviso do propósito do bloco).\n",
    "# Gera métricas de classificação no conjunto de teste.\n",
    "\n",
    "# Coloca a rede em modo de avaliação (desativa dropout e usa BN com estatísticas fixas).\n",
    "net.eval()\n",
    "\n",
    "# Inicializa listas para acumular previsões e rótulos de todos os lotes.\n",
    "predicoes, alvos = [], []\n",
    "\n",
    "# Desativa o cálculo de gradientes para acelerar a inferência e economizar memória.\n",
    "with torch.no_grad():\n",
    "    # Itera pelos lotes do loader de teste, recebendo imagens e rótulos verdadeiros.\n",
    "    for imagens, rotulos in test_loader:\n",
    "        # Move o batch de imagens para o dispositivo (CPU/GPU) configurado.\n",
    "        imagens = imagens.to(args['device'])\n",
    "        # Move os rótulos para o mesmo dispositivo.\n",
    "        rotulos = rotulos.to(args['device'])\n",
    "        # Forward: calcula os logits/saídas do modelo para o batch.\n",
    "        saidas = net(imagens)\n",
    "        # Converte logits em classes previstas (índice do maior logit por amostra).\n",
    "        preds = saidas.argmax(dim=1)\n",
    "        # Armazena as predições no CPU como NumPy para posterior concatenação.\n",
    "        predicoes.append(preds.cpu().numpy())\n",
    "        # Armazena os rótulos verdadeiros no CPU como NumPy.\n",
    "        alvos.append(rotulos.cpu().numpy())\n",
    "\n",
    "# Concatena todos os rótulos em um único vetor 1D (ordem dos lotes preservada).\n",
    "y_true = np.concatenate(alvos)\n",
    "# Concatena todas as predições em um único vetor 1D.\n",
    "y_pred = np.concatenate(predicoes)\n",
    "# Obtém os nomes de classe (CIFAR-10: airplane, automobile, …) do dataset de treino.\n",
    "class_names = train_set.classes\n",
    "\n",
    "# Imprime um cabeçalho textual para o relatório de classificação.\n",
    "print('Relatório de classificação (teste):')\n",
    "# Gera precisão/recall/F1 por classe; requer: from sklearn.metrics import classification_report.\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Calcula a matriz de confusão (linhas = verdade, colunas = predito).\n",
    "# Requer: from sklearn.metrics import confusion_matrix.\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Abre uma figura para o heatmap da matriz de confusão.\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plota a matriz de confusão como heatmap com rótulos nas bordas; requer: import seaborn as sns.\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "# Define um título descritivo para o gráfico da matriz de confusão.\n",
    "plt.title('Matriz de confusão - Teste')\n",
    "\n",
    "# Rotula o eixo Y como “classe verdadeira”.\n",
    "plt.ylabel('Classe verdadeira')\n",
    "\n",
    "# Rotula o eixo X como “classe predita”.\n",
    "plt.xlabel('Classe predita')\n",
    "\n",
    "# Ajusta margens/espaçamentos para evitar cortes de textos.\n",
    "plt.tight_layout()\n",
    "\n",
    "# Renderiza o heatmap na saída.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55502757",
   "metadata": {
    "name": "ema_init"
   },
   "outputs": [],
   "source": [
    "# >>> EMA (Exponential Moving Average) dos pesos\n",
    "import copy, torch\n",
    "\n",
    "use_ema = True\n",
    "ema_decay = 0.999\n",
    "\n",
    "try:\n",
    "    ema_net = copy.deepcopy(net).to(args['device'])\n",
    "    for p in ema_net.parameters():\n",
    "        p.requires_grad = False\n",
    "    print(\"EMA pronta (decay=0.999).\")\n",
    "except Exception as e:\n",
    "    print(\"Crie o modelo 'net' antes de executar a EMA:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84ed1b",
   "metadata": {
    "name": "eval_helper"
   },
   "outputs": [],
   "source": [
    "# >>> Funções auxiliares para avaliar perda/acurácia\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_loss_acc(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            losses.append(loss.item())\n",
    "            preds = logits.argmax(dim=1)\n",
    "            y_true.append(y.cpu())\n",
    "            y_pred.append(preds.cpu())\n",
    "    import torch as _torch\n",
    "    y_true = _torch.cat(y_true).numpy()\n",
    "    y_pred = _torch.cat(y_pred).numpy()\n",
    "    acc = accuracy_score(y_true, y_pred) * 100.0\n",
    "    return float(np.mean(losses)), float(acc)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Treino-do-zero-Gabarito.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
